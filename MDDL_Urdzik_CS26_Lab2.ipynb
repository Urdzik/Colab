{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Urdzik/Colab/blob/main/MDDL_Urdzik_CS26_Lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83HTNYizt4EN",
        "outputId": "7d2795d0-12c3-4523-a17d-55ef1db75004",
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [],
      "source": [
        "!pip install --quiet datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating train split: 100%|██████████| 560000/560000 [00:00<00:00, 1800260.17 examples/s]\n",
            "Generating test split: 100%|██████████| 38000/38000 [00:00<00:00, 1741687.36 examples/s]\n"
          ]
        }
      ],
      "source": [
        "yelp_polarity  = datasets.load_dataset(\"yelp_polarity\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 560000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 38000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "yelp_polarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['train', 'test'])\n"
          ]
        }
      ],
      "source": [
        "print(yelp_polarity.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = yelp_polarity['train']\n",
        "# test_data = yelp_polarity['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 560000\n",
              "})"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In general I do like Shake N' Steak, but this location is a hit or miss location!  You never know what kind of quality or service you're going to find here.  A friend and myself went a few weeks back after a movie and it had to be one of the worst trips there EVER!  You can't entirely blame the waitress since she was the only one there for the entire place...poor scheduling on the manager's part. However, while she can't be accountable for the slooooow service, she was accountable for both orders being incorrect.  The burgers were over cooked and the fries were soggie and the milkshake was runny at best...\\\\n\\\\nBy far my worst visit to Steak n' Shake!\""
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[100][\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --quiet spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['I',\n",
              " 'ca',\n",
              " \"n't\",\n",
              " 'find',\n",
              " 'my',\n",
              " '$',\n",
              " '25',\n",
              " '!',\n",
              " 'oleksiy@google.com',\n",
              " 'http://google.com/',\n",
              " '<',\n",
              " 'b',\n",
              " '>']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import spacy\n",
        "import tqdm\n",
        "from typing import List, Tuple\n",
        "\n",
        "spacy_nlp = spacy.blank(\"en\")\n",
        "\n",
        "def tokenize_spacy(text: str) -> List[str]:\n",
        "  \"\"\"Tokenize string with SpaCy. \"\"\"\n",
        "\n",
        "  tokens = spacy_nlp.tokenizer(text)\n",
        "  return [str(token) for token in tokens]\n",
        "\n",
        "\n",
        "def tokenize(text: str) -> List[str]:\n",
        "  return tokenize_spacy(text)\n",
        "\n",
        "\n",
        "tokenize_spacy(\"I can't find my $25! oleksiy@google.com http://google.com/ <b>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pystemmer\n",
            "  Downloading pystemmer-3.0.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
            "Downloading pystemmer-3.0.0-cp311-cp311-macosx_11_0_arm64.whl (240 kB)\n",
            "Installing collected packages: pystemmer\n",
            "Successfully installed pystemmer-3.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pystemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i do n't know what dr. goldberg was like befor   move to arizona , but let me tell you , stay away from this doctor and this offic . i was go to dr. johnson befor he left and goldberg took over when johnson left . he is not a care doctor . he is onli interest in the co - pay and have you come in for medic refil everi month . he will not give refil and could less about patient 's financi situat . tri to get your 90 day mail away pharmaci prescript through this guy is a joke . and to make matter even wors , his offic staff is incompet . 90 % of the time when you call the offic , they ll put you through to a voic mail , that no one ever answer or return your call . both my adult children and husband have decid to leav this practic after experienc such frustrat . the entir offic has an attitud like they are do you a favor . give me a break ! stay away from this doc and the practic . you deserv better and they will not be there when you realli need them . i have never felt compel to write a bad review about anyon until i met this pathet excus for a doctor who is all about the money .\n"
          ]
        }
      ],
      "source": [
        "import Stemmer\n",
        "from typing import List\n",
        "\n",
        "def stem(tokens: List[str]) -> List[str]:\n",
        "  \"\"\"Lower-case and stem tokens. \"\"\"\n",
        "\n",
        "  stemmer = Stemmer.Stemmer(\"english\")\n",
        "  tokens = [tok.lower() for tok in tokens]\n",
        "  return stemmer.stemWords(tokens)\n",
        "\n",
        "example_tokens = tokenize(train_data[2][\"text\"])\n",
        "stemmed_tokens = stem(example_tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sing                   =>   sing\n",
            "sings                  =>   sing\n",
            "singing                =>   sing\n",
            "singer                 =>   singer\n",
            "singers                =>   singer\n"
          ]
        }
      ],
      "source": [
        "for word in (\"sing\", \"sings\", \"singing\", \"singer\", \"singers\"):\n",
        "  stemmed = stem([word])[0]\n",
        "  print(f\"{word:<20}   =>   {stemmed}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 45980/560000 [00:10<01:44, 4898.09it/s]"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "all_tokens = []\n",
        "all_tokens_stemmed = []\n",
        "for doc in tqdm(train_data):\n",
        "  doc_tokens = tokenize(doc[\"text\"])\n",
        "  all_tokens += doc_tokens\n",
        "  all_tokens_stemmed += stem(doc_tokens)\n",
        "\n",
        "print(\"Original unique tokens: {:,}\".format(len(set(all_tokens))))\n",
        "print(\"Stemmed  unique tokens: {:,}\".format(len(set(all_tokens_stemmed))))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
